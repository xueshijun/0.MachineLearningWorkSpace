{
 "metadata": {
  "name": "",
  "signature": "sha256:9ed9d99be3a258067240294d509eed792d8ba10667b78e6a372ec43387d39843"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\u7b2c5\u7ae0 \u6316\u6398\u7f51\u9875\uff1a\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7406\u89e3\u4eba\u7c7b\u8bed\u8a00\u3001\u603b\u7ed3\u535a\u5ba2\u5185\u5bb9\u7b49 167\n",
      "5.1 \u6982\u8ff0 168\n",
      "5.2 \u6293\u53d6\u3001\u89e3\u6790\u3001\u722c\u53d6\u7f51\u9875 168\n",
      "5.3 \u901a\u8fc7\u89e3\u7801\u8bed\u6cd5\u6765\u63a2\u7d22\u8bed\u4e49 174\n",
      "5.4 \u4ee5\u5b9e\u4f53\u4e3a\u4e2d\u5fc3\u7684\u5206\u6790\uff1a\u8303\u5f0f\u8f6c\u6362 192\n",
      "5.5 \u4eba\u7c7b\u8bed\u8a00\u6570\u636e\u5904\u7406\u5206\u6790\u7684\u8d28\u91cf 200\n",
      "5.6 \u672c\u7ae0\u5c0f\u7ed3 203\n",
      "5.7 \u63a8\u8350\u7ec3\u4e60 203\n",
      "5.8 \u5728\u7ebf\u8d44\u6e90 204"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "pip install boilerpipe\n",
      "\u57fa\u4e8ejava\u7684,\u4e3a\u4e86\u8bc6\u522b\u548c\u79fb\u9664\u7f51\u9875\u4e2d\u7684\u6837\u677f\u800c\u8bbe\u8ba1\u7684"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example 1. \u4f7f\u7528boilerpipe\u4ece\u7f51\u9875\u4e2d\u63d0\u53d6\u6587\u672c"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "from boilerpipe.extract import Extractor\n",
      "\n",
      "URL='http://blog.csdn.net/geekmanong/article/details/50517909'\n",
      "\n",
      "extractor = Extractor(extractor='ArticleExtractor', url=URL)\n",
      "\n",
      "print extractor.getText()"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example 2. \u4f7f\u7528feedparser\u4eceRSS or Atom\u8ba2\u9605\u4e2d\u63d0\u53d6\u6587\u672c"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "pip install feedparser"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import feedparser\n",
      "\n",
      "FEED_URL='http://feeds.feedburner.com/oreilly/radar/atom'\n",
      "\n",
      "fp = feedparser.parse(FEED_URL)\n",
      "\n",
      "for e in fp.entries:\n",
      "    print e.title\n",
      "    print e.links[0].href\n",
      "    print e.content[0].value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Four short links: 24 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/NRQff7YHqFA/four-short-links-24-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://everythingsysadmin.com/2016/03/two-github-accounts.html\">Maintain Separate Github Accounts</a> -- simple advice.</li>\n",
        "<li><a href=\"https://github.com/cooperhewitt/the-pen-data\">Cooper-Hewitt Pen Data</a> -- anonymized data from the Cooper-Hewitt design museum's fantastic <a href=\"http://www.cooperhewitt.org/new-experience/designing-pen/\">pen</a>.</li>\n",
        "<li><a href=\"http://motherboard.vice.com/read/wikipedia-zero-facebook-free-basics-angola-pirates-zero-rating\">Zero Rating's Problem</a> -- Wikipedia was zero-rated for Angola, so Angolans began swapping movies via Wikipedia. Zero rating (\"no data charge for this service\") is an incentive to use the site, not necessarily for the purpose intended.</li>\n",
        "<li><a href=\"https://blog.prototypr.io/motion-design-is-the-future-of-ui-fc83ce55c02f#.gssflde77\">Motion Design is the Future of UI</a> -- <i>Motion tells stories. Everything in an app is a sequence, and motion is your guide</i>. Someone caught the animations and transitions bug.</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=NRQff7YHqFA:ZTWlBv9p834:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=NRQff7YHqFA:ZTWlBv9p834:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=NRQff7YHqFA:ZTWlBv9p834:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=NRQff7YHqFA:ZTWlBv9p834:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=NRQff7YHqFA:ZTWlBv9p834:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=NRQff7YHqFA:ZTWlBv9p834:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=NRQff7YHqFA:ZTWlBv9p834:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/NRQff7YHqFA\" width=\"1\" />\n",
        "Four short links: 23 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/rTJpr2_moqA/four-short-links-23-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"https://code.facebook.com/posts/1737605303120405/dragon-a-distributed-graph-query-engine/\">Dragon: A Distributed Graph Query Engine</a> -- Facebook describes its internal graph query engine. <i>[T]he layout of these indices on storage is optimized based on a deeper understanding of query patterns (e.g., many queries are about friends), as opposed to accepting random sharding, which is common in these systems.</i> Wisely, the system is tailored to the use cases they have and the patterns they see in access.</li>\n",
        "<li><a href=\"http://techcrunch.com/2016/03/21/almost-everyone-is-doing-the-api-economy-wrong/\">Almost Everyone Is Doing the API Economy Wrong</a> (Techcrunch) -- Redux: your API should help you make money when the API customer makes money, and you should set clear expectations for what's acceptable and what's not. But every developer should be forced to write 100 times: \"if you build on a platform you don't own, you're building on a potential and probable future competitor.\"</li>\n",
        "<li><a href=\"http://evonomics.com/traditional-economics-failed-heres-a-new-blueprint/\">Traditional Economics Failed, Here's a Blueprint</a> -- runs through the shifts happening in our thinking about the world and ourselves (simple to complex, independent to interdependent, rational calculator to irrational approximators, etc) and concludes: <i>True self-interest is mutual interest. The best way to improve your likelihood of surviving and thriving is to make sure those around you survive and thrive.</i> See above API note.</li>\n",
        "<li><a href=\"https://hbr.org/2016/04/blitzscaling\">Blitzscaling</a> (HBR) -- <i>as you move from village to city, functions are beginning to be differentiated; you\u2019re really multithreading.</i> I could write a thesis on the CAP theorem for business. And I have definitely worked for companies that have a \"share nothing\" approach to solving their threading issues.</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=rTJpr2_moqA:_Ri6sCDhBSg:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=rTJpr2_moqA:_Ri6sCDhBSg:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=rTJpr2_moqA:_Ri6sCDhBSg:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=rTJpr2_moqA:_Ri6sCDhBSg:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=rTJpr2_moqA:_Ri6sCDhBSg:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=rTJpr2_moqA:_Ri6sCDhBSg:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=rTJpr2_moqA:_Ri6sCDhBSg:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/rTJpr2_moqA\" width=\"1\" />\n",
        "Four short links: 22 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/hU475_FPzEs/four-short-links-22-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"https://hcipioneers.wordpress.com/\">HCI Pioneers</a> -- Ben Schneiderman's photo collection, acknowledging pioneers in the field. (via <a href=\"http://www.cccblog.org/2016/03/21/encounters-with-hci-pioneers-a-personal-photo-journal/\">CCC Blog</a>)</li>\n",
        "<li><a href=\"http://www.bldgblog.com/2016/03/a-burglars-guide-to-the-city/\">A Burglar's Guide to the City</a> (BLDGBLOG) -- <i>For the past several years, I\u2019ve been writing a book about the relationship between burglary and architecture. Burglary, as it happens, requires architecture: it is a spatial crime. Without buildings, burglary, in its current legal form, could not exist. Committing it requires an inside and an outside; it\u2019s impossible without boundaries, thresholds, windows, and walls. In fact, one needn\u2019t steal anything at all to be a burglar. In a sense, as a crime, it is part of the built environment; the design of any structure always implies a way to break into it.</i> Connection to computer security left as exercise to the reader.</li>\n",
        "<li><a href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2743800\">Trial by Machine</a> (Roth) -- <i>The current landscape of mechanized proof, liability, and punishment suffers from predictable but underscrutinized automation pathologies: hidden subjectivities and errors in \u201cblack box\u201d processes; distorted decision-making through oversimplified \u2014 and often dramatically inaccurate \u2014 proxies for blameworthiness; the compromise of values protected by human safety valves, such as dignity, equity, and mercy; and even too little mechanization where machines might be a powerful debiasing tool but where little political incentive exists for its development or deployment. [...] The article ultimately proposes a systems approach \u2013 \u201ctrial by cyborg\u201d \u2013 that safeguards against automation pathologies while interrogating conspicuous absences in mechanization through \u201cequitable surveillance\u201d and other means.</i> (via <a href=\"http://marginalrevolution.com/marginalrevolution/2016/03/monday-assorted-links-49.html\">Marginal Revolution</a>)</li>\n",
        "<li><a href=\"https://www.gov.uk/government/publications/distributed-ledger-technology-blackett-review\">Distributed Ledger Technology: Blackett Review</a> (gov.uk) -- <i>Distributed ledgers can provide new ways of assuring ownership and provenance for goods and intellectual property. For example, Everledger provides a distributed ledger that assures the identity of diamonds, from being mined and cut to being sold and insured. In a market with a relatively high level  of paper forgery, it makes attribution more efficient, and has the potential to reduce fraud and prevent \"blood diamonds\" from entering the market.</i> Report includes recommendations for policy makers. (via <a href=\"https://twitter.com/cityofsound/status/712048001821315072\">Dan Hill</a>)</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=hU475_FPzEs:45lFpdiq68s:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=hU475_FPzEs:45lFpdiq68s:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=hU475_FPzEs:45lFpdiq68s:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=hU475_FPzEs:45lFpdiq68s:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=hU475_FPzEs:45lFpdiq68s:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=hU475_FPzEs:45lFpdiq68s:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=hU475_FPzEs:45lFpdiq68s:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/hU475_FPzEs\" width=\"1\" />\n",
        "Four short links: 21 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/rWHXDeq8mZo/four-short-links-21-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://www.chyp.com/ten-more-years-ten-more-years/\">Ten More Years!</a> -- <i>my brand spanking new chip card from a UK issuer not only arrived with a 2000s app of a 1990s implementation of a 1980s product (debit) on 1970s chip, it also came with a 1960s magnetic stripe on it and a 1950s PAN with a 1940s signature panel on the back. It\u2019s no wonder it seems a little out of place in the modern world. </i></li>\n",
        "<li><a href=\"http://gitxiv.com/posts/sKTDSvwzoiRaojLG6/age-and-gender-classification-using-convolutional-neural\">Age and Gender Classification Using Convolutional Neural Nets</a> -- oh, this will end well.</li>\n",
        "<li><a href=\"https://medium.com/@rossgoodwin/adventures-in-narrated-reality-6516ff395ba3#.9ak4u6ino\">The Uncanny Valley of Words</a> (Ross Goodwin) -- lessons learned from an NYU ITP neural networker making poetry and surprises from text.</li>\n",
        "<li><a href=\"https://www.youtube.com/watch?v=_Az608TI-NI&amp;feature=youtu.be\">The Paradox of Human Performance</a> (YouTube) -- <i>Human dexterity and agility vastly exceed that of contemporary robots. Yet, humans have vastly slower \"hardware\" (e.g. muscles) and \"wetware\" (e.g. neurons). How can this paradox be resolved? Slow actuators and long communication delays require predictive control based on some form of internal model\u2014but what form?</i> (via <a href=\"http://robohub.org/neville-hogan-the-paradox-of-human-performance-cmu-ri-seminar/\">Robohub</a>)</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=rWHXDeq8mZo:rezrmcUUubA:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=rWHXDeq8mZo:rezrmcUUubA:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=rWHXDeq8mZo:rezrmcUUubA:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=rWHXDeq8mZo:rezrmcUUubA:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=rWHXDeq8mZo:rezrmcUUubA:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=rWHXDeq8mZo:rezrmcUUubA:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=rWHXDeq8mZo:rezrmcUUubA:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/rWHXDeq8mZo\" width=\"1\" />\n",
        "Four short links: 18 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/OTVGJjwfCIs/four-short-links-18-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://marginalrevolution.com/marginalrevolution/2016/03/engineers-of-jihad.html\">Engineers of Jihad</a> (Marginal Revolution) -- brief book review, tantalizing. <i>The distribution of traits across disciplines mirrors almost exactly the distribution of disciplines across militant groups\u2026engineers are present in groups in which social scientists, humanities graduates, and women are absent, and engineers possess traits \u2014 proneness to disgust, need for closure, in-group bias, and (at least tentatively) simplism\u2026</i></li>\n",
        "<li><a href=\"http://ieet.org/index.php/IEET/more/searle20160318#When:07:36:00Z\">Box of a Trillion Souls</a> -- review and critique of some of Stephen Wolfram's writing and speaking about AI and simulation and the nature of reality and complexity and ... a lot.</li>\n",
        "<li><a href=\"http://www.nytimes.com/2016/03/18/technology/cities-to-untangle-traffic-snarls-with-help-from-alphabet-unit.html\">Alphabet Starting Sidewalk Labs</a> (NY Times) -- <i>\u201cWe\u2019re taking everything from anonymized smartphone data from billions of miles of trips, sensor data, and bringing that into a platform that will give both the public and private parties and government the capacity to actually understand the data in ways they haven\u2019t before,\u201d said Daniel L. Doctoroff, Sidewalk\u2019s chief executive, who is a former deputy mayor of New York City and former chief executive of Bloomberg.</i> Data, data, data.</li>\n",
        "<li><a href=\"http://sigbovik.org/\">SIGBOVIK</a> -- the <a href=\"http://sigbovik.org/2015/proceedings.pdf\">proceedings from 2015</a> include a paper that talks about \"The Tortilla Endofunctor.\" You're welcome.</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=OTVGJjwfCIs:8R-DtGCpRSA:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=OTVGJjwfCIs:8R-DtGCpRSA:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=OTVGJjwfCIs:8R-DtGCpRSA:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=OTVGJjwfCIs:8R-DtGCpRSA:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=OTVGJjwfCIs:8R-DtGCpRSA:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=OTVGJjwfCIs:8R-DtGCpRSA:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=OTVGJjwfCIs:8R-DtGCpRSA:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/OTVGJjwfCIs\" width=\"1\" />\n",
        "Four short links: 17 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/eA1wpnbYhUs/four-short-links-17-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"https://www.technologyreview.com/s/601051/machine-learning-algorithm-identifies-tweets-sent-under-the-influence-of-alcohol/\">Algorithm Identifies Tweets Sent Under the Influence of Alcohol</a> (MIT TR) -- notable for how they determined whether a Tweet was sent from home. They made a list of phrases like \"home at last!\" and had MTurkers confirm the Tweets were about being home, then used those as training data for an algorithm to identify other Tweets talking about home.</li>\n",
        "<li><a href=\"https://www.newscientist.com/article/2080200-puzzle-game-launched-to-help-program-quantum-computers/\">Puzzle Game to Help Program Quantum Computers</a> (New Scientist) -- <i>Devitt has turned the problem of programming a quantum computer into a game called meQuanics. His team has developed a prototype to test the game, which you can play now, and today launched a Kickstarter campaign to fund a fully fledged version for iOS and Android phones.</i></li>\n",
        "<li><a href=\"http://cacm.acm.org/magazines/2016/3/198856-deep-or-shallow-nlp-is-breaking-out/fulltext\">Deep or Shallow, NLP is Breaking Out</a> (ACM) -- readable roundup of how NLP changed in the last five years, with a useful list for further reading and watching.</li>\n",
        "<li><a href=\"https://zachholman.com/talk/firing-people\">Firing and Being Fired</a> (Zach Holman) -- advice for the fired, the firing, and the coworkers. All solid.</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=eA1wpnbYhUs:XdoaMUkFVho:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=eA1wpnbYhUs:XdoaMUkFVho:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=eA1wpnbYhUs:XdoaMUkFVho:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=eA1wpnbYhUs:XdoaMUkFVho:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=eA1wpnbYhUs:XdoaMUkFVho:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=eA1wpnbYhUs:XdoaMUkFVho:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=eA1wpnbYhUs:XdoaMUkFVho:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/eA1wpnbYhUs\" width=\"1\" />\n",
        "Four short links: 16 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Jg71f0gxf54/four-short-links-16-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"https://github.com/stanford-futuredata/macrobase\">MacroBase</a> -- <i>Analytic monitoring for the Internet of Things</i>. The code behind <a href=\"http://arxiv.org/pdf/1603.00567v1.pdf\">a research paper</a>, written up in <a href=\"http://blog.acolyer.org/2016/03/16/macrobase-analytic-monitoring-for-the-internet-of-things/\">the morning paper</a> where Adrian Colyer says, <i> there is another story that also unfolds in the paper \u2013 one of careful system design based on analysis of properties of the problem space, of thinking deeply and taking the time to understand the prior art (aka \"the literature\"), and then building on those discoveries to advance and adapt them to the new situation. \u201cThat\u2019s what research is all about!\u201d you may say, but it\u2019s also what we\u2019d (I\u2019d?) love to see more of in practitioner settings, too. The result of all this hard work is a system that comprises just 7,000 lines of code, and I\u2019m sure, many, many hours of thinking!</i></li>\n",
        "<li><a href=\"http://engagingnewsproject.org/research/survey-of-commenters-and-comment-readers/\">Survey of Commenters and Comment Readers</a> -- <i>Americans who leave news comments, who read news comments, and who do neither are demographically distinct. News commenters are more male, have lower levels of education, and have lower incomes compared to those who read news comments.</i> (via <a href=\"http://marginalrevolution.com/marginalrevolution/2016/03/sentences-to-ponder-who-leaves-on-line-comments.html\">Marginal Revolution</a>)</li>\n",
        "<li><a href=\"http://www.nature.com/articles/srep23011\">The Empathizing-Systemizing Theory, Social Abilities, and Mathematical Achievement in Children</a> (Nature) -- systematic thinking doesn't predict math ability in children, but being empathetic predicts being worse at math. The effect is stronger with girls. The authors propose the mechanism is that empathetic children pick up a teacher's own dislike of math, and any teacher biases like \"girls aren't good at math.\"</li>\n",
        "<li><a href=\"http://www.nytimes.com/2016/03/15/business/media/moneyball-for-book-publishers-for-a-detailed-look-at-how-we-read.html\">Moneyball for Book Publishers: A Detailed Look at How We Read</a> (NYT) -- <i>On average, fewer than half of the books tested were finished by a majority of readers. Most readers typically give up on a book in the early chapters. Women tend to quit after 50 to 100 pages, men after 30 to 50. Only 5% of the books Jellybooks tested were completed by more than 75% of readers. Sixty percent of books fell into a range where 25% to 50% of test readers finished them. Business books have surprisingly low completion rates.</i> Not surprisingly low to anyone who has ever read a business book. They're always a 20-page idea stretched to 150 pages because that's how wide a book's spine has to be to visible on the airport bookshelf. Fat paper stock and 14-point text with wide margins and 1.5 line spacing help, too. Don't forget to leave pages after each chapter for the reader's notes. And summary checklists. And ... sorry, I need to take a moment.</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=Jg71f0gxf54:0CyQCnRayRo:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=Jg71f0gxf54:0CyQCnRayRo:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=Jg71f0gxf54:0CyQCnRayRo:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=Jg71f0gxf54:0CyQCnRayRo:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=Jg71f0gxf54:0CyQCnRayRo:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=Jg71f0gxf54:0CyQCnRayRo:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=Jg71f0gxf54:0CyQCnRayRo:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/Jg71f0gxf54\" width=\"1\" />\n",
        "Four short links: 15 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/cnEFSjPf0-o/four-short-links-15-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://www.amazon.com/The-Car-Hackers-Handbook-Penetration/dp/1593277032/ref=as_li_ss_tl?ie=UTF8&amp;linkCode=sl1&amp;tag=downandoutint-20&amp;linkId=4a8a3937db21d334c8ca0eb18c16c72d\">The 2016 Car Hacker's Handbook</a> (Amazon) -- <i>will give you a deeper understanding of the computer systems and embedded software in modern vehicles. It begins by examining vulnerabilities and providing detailed explanations of communications over the CAN bus and between devices and systems.</i> (via <a href=\"http://boingboing.net/2016/03/14/the-car-hackersthe-car-hacke.html\">BoingBoing</a>)</li>\n",
        "<li><a href=\"http://robohub.org/indego-joins-ekso-with-fda-exoskeleton-approvals/\">More Exoskeletons Seeking FDA Approval</a> -- <i>The international group of exoskeleton providers with various FDA or CE certifications is growing and currently includes: Ekso in the US; Cyberdyne in the EU and Japan; ExoAtlet from Russia; and Israel\u2019s ReWalk. Other providers are in the process of getting approvals or developing commercial versions of their products.</i> My eye was caught by how global the list of exoskeleton companies is.</li>\n",
        "<li><a href=\"https://github.com/pythonanywhere/dirigible-spreadsheet\">Dirigible Spreadsheet</a> -- open source spreadsheet that's not just written in Python, it exposes and IS python.  See also <a href=\"https://www.youtube.com/watch?v=BbsdFGo6SzY\">Harry Percival</a> talking about it.</li>\n",
        "<li><a href=\"http://gizmodo.com/everything-you-know-about-artificial-intelligence-is-wr-1764020220\">Everything You Know About AI Is Wrong</a> (Gizmodo) -- an interesting run-through of myths and claims about AI.  I'm not ready to consider all of these \"busted,\" but they are some nice starters-for-ten in your next pub argument about whether the Matrix is coming.</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=cnEFSjPf0-o:JjZKECXUdho:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=cnEFSjPf0-o:JjZKECXUdho:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=cnEFSjPf0-o:JjZKECXUdho:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=cnEFSjPf0-o:JjZKECXUdho:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=cnEFSjPf0-o:JjZKECXUdho:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=cnEFSjPf0-o:JjZKECXUdho:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=cnEFSjPf0-o:JjZKECXUdho:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/cnEFSjPf0-o\" width=\"1\" />\n",
        "Four short links: 14 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/e-R4P2fDe2I/four-short-links-14-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://fredrikdeboer.com/2016/03/07/what-thomas-hardy-taught-me/\">What Thomas Hardy Taught Me</a> -- <i>In educational research, perhaps the greatest danger lies in thinking \u201cthat which I cannot measure is not real.\u201d The disruption fetishists have amplified this danger, now evincing the attitude \u201cteaching that cannot be said to lead to the immediate acquisition of rote, mechanical skills has no value.\u201d But absolutely every aspect of my educational journey \u2014 as a student, as a teacher, and as a researcher \u2014 demonstrates the folly of this approach to learning.</i> (via <a href=\"http://blog.mrmeyer.com/2016/silicon-valley-v-the-liberal-arts/\">Dan Meyer</a>)</li>\n",
        "<li><a href=\"http://pubpub.ito.com/pub/dmca-drm-aml-kyc-backdoors\">Why Anti-Money Laundering Laws and Poorly Designed Copyright Laws Are Similar and Should be Revised</a> (Joi Ito) -- <i>Just like with the Internet, weaknesses in networks like the blockchain propagate to countries and regions where privacy risks to users could cause significant risks to human rights workers, journalists, or anyone who questions authority. The conversation on creating new AML and KYC laws for new financial systems like bitcoin and blockchain needs to be a global one.</i></li>\n",
        "<li><a href=\"http://blog.acolyer.org/2016/03/14/secrets-lies-and-account-recovery-lessons-from-the-use-of-personal-knowledge-questions-at-google/\">Secrets, Lies, and Account Recovery: Lessons from the Use of Personal Knowledge Questions at Google</a> -- Adrian Colyer summarizes a paper from Google. <i>Using a crowdsourcing service, the authors asked 1,000 users to answer the \u2018Favourite Food\u2019 and \u2018Father\u2019s middle name\u2019 questions. This took less than a day and cost $100. [...] Using a single guess, it turns out, you have a 19.7% chance of guessing an English-speaking users\u2019 answer to the favourite food.</i></li>\n",
        "<li><a href=\"http://www.roadtovr.com/mts-virtual-reality-vr-tracking-system-jack-mccauley-oculus-vp-engineering/\">Clever MEMS 3D Object Tracking</a> -- early Oculus engineer has invented a nifty way to track a tagged object in 3D space. Worth reading for the description of how it works.</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=e-R4P2fDe2I:sQKRrJRRLL0:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=e-R4P2fDe2I:sQKRrJRRLL0:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=e-R4P2fDe2I:sQKRrJRRLL0:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=e-R4P2fDe2I:sQKRrJRRLL0:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=e-R4P2fDe2I:sQKRrJRRLL0:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=e-R4P2fDe2I:sQKRrJRRLL0:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=e-R4P2fDe2I:sQKRrJRRLL0:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/e-R4P2fDe2I\" width=\"1\" />\n",
        "Four short links: 11 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/fl2qjDQ_KxA/four-short-links-11-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://blog.acolyer.org/2016/03/11/strategic-dialogue-management-via-deep-reinforcement-learning/\">Strategic Dialogue Management via Deep Reinforcement Learning</a> (Adrian Colyer) -- a neural network learns to play Settlers of Catan. Is nothing sacred?</li>\n",
        "<li><a href=\"http://twitter.github.io/scala_school/\">scala school</a> -- Twitter's instructional material for coming up to speed on scala.</li>\n",
        "<li><a href=\"https://labs.robinhood.org/fellowship/\">Robin Hood Fellowship</a> -- fellowship to use technology to increase access to legal services for New Yorkers. Stuff that matters.</li>\n",
        "<li><a href=\"http://www.nytimes.com/2016/03/10/technology/the-echo-from-amazon-brims-with-groundbreaking-promise.html\">The Echo From Amazon Brims With Groundbreaking Promise</a> (NY Times) -- <i>A bit more than a year after its release, the Echo has morphed from a gimmicky experiment into a device that brims with profound possibility. The longer I use it, the more regularly it inspires the same sense of promise I felt when I used the first iPhone \u2014 a sense this machine is opening up a vast new realm in personal computing, and gently expanding the role that computers will play in our future.</i></li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=fl2qjDQ_KxA:6SW6v9Vpq14:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=fl2qjDQ_KxA:6SW6v9Vpq14:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=fl2qjDQ_KxA:6SW6v9Vpq14:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=fl2qjDQ_KxA:6SW6v9Vpq14:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=fl2qjDQ_KxA:6SW6v9Vpq14:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=fl2qjDQ_KxA:6SW6v9Vpq14:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=fl2qjDQ_KxA:6SW6v9Vpq14:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/fl2qjDQ_KxA\" width=\"1\" />\n",
        "Four short links: 10 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/_-RgC4gdmvA/four-short-links-10-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://www.cam.ac.uk/research/news/ai-crossword-solving-application-could-make-machines-better-at-understanding-language\">Crossword-Solving Neural Networks</a> -- <i>Hill describes recent progress in learning-based AI systems in terms of behaviourism and cognitivism: two movements in psychology that effect how one views learning and education. Behaviourism, as the name implies, looks at behaviour without looking at what the brain and neurons are doing, while cognitivism looks at the mental processes that underlie behaviour. Deep learning systems like the one built by Hill and his colleagues reflect a cognitivist approach, but for a system to have something approaching human intelligence, it would have to have a little of both. \u201cOur system can\u2019t go too far beyond the dictionary data on which it was trained, but the ways in which it can are interesting, and make it a surprisingly robust question and answer system \u2013 and quite good at solving crossword puzzles,\u201d said Hill. While it was not built with the purpose of solving crossword puzzles, the researchers found that it actually performed better than commercially-available products that are specifically engineered for the task.</i></li>\n",
        "<li><a href=\"http://cra.org/ccc/wp-content/uploads/sites/2/2015/06/CCC-Social-Computing-Report.pdf\">Mathematical Foundations for Social Computing</a> (PDF) -- collection of pointers to existing research in social computing and some open challenges for work to be done. <i>Consider situations where a highly structured decision must be made. Some examples are making budgets, assigning water resources, and setting tax rates. [...] One promising candidate is \u201cKnapsack Voting.\u201d [...] This captures most budgeting processes \u2014 the set of chosen budget items must fit under a spending limit, while maximizing societal value. <a href=\"http://web.stanford.edu/~anilesh/publications/knapsack_voting.pdf\">Goel et al.</a> prove that asking users to compare projects in terms of \u201cvalue for money\u201d or asking them to choose an entire budget results in provably better properties than using the more traditional approaches of approval or rank-choice voting.</i></li>\n",
        "<li><a href=\"https://blog.twitter.com/2016/power-minimal-detectable-effect-and-bucket-size-estimation-in-ab-tests\">Power, Minimal Detectable Effect, and Bucket Size Estimation in A/B Tests</a> (Twitter) -- <i>This post describes how Twitter\u2019s A/B testing framework, DDG, addresses one of the most common questions we hear from experimenters, product managers, and engineers: how many users do we need to sample in order to run an informative experiment?</i></li>\n",
        "<li><a href=\"http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0147754\">Intelligence-Augmented Rat Cyborgs in Maze Solving</a> (PLoS) -- <i>We compare the performance of maze solving by computer, by individual rats, and by computer-aided rats (i.e. rat cyborgs). They were asked to find their way from a constant entrance to a constant exit in 14 diverse mazes. Performance of maze solving was measured by steps, coverage rates, and time spent. The experimental results with six rats and their intelligence-augmented rat cyborgs show that rat cyborgs have the best performance in escaping from mazes. These results provide a proof-of-principle demonstration for cyborg intelligence. In addition, our novel cyborg intelligent system (rat cyborg) has great potential in various applications, such as search and rescue in complex terrains.</i></li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=_-RgC4gdmvA:w2iGTUQNByY:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=_-RgC4gdmvA:w2iGTUQNByY:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=_-RgC4gdmvA:w2iGTUQNByY:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=_-RgC4gdmvA:w2iGTUQNByY:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=_-RgC4gdmvA:w2iGTUQNByY:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=_-RgC4gdmvA:w2iGTUQNByY:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=_-RgC4gdmvA:w2iGTUQNByY:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/_-RgC4gdmvA\" width=\"1\" />\n",
        "Four short links: 9 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/a72V_CKUuG0/four-short-links-9-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://www.faz.net/aktuell/feuilleton/debatten/the-digital-debate/shoshana-zuboff-secrets-of-surveillance-capitalism-14103616-p2.html?printPagedArticle=true\">The Secrets of Surveillance Capitalism</a> -- <i>The assault on behavioral data is so sweeping that it can no longer be circumscribed by the concept of privacy and its contests. [...] First, the push for more users and more channels, services, devices, places, and spaces is imperative for access to an ever-expanding range of behavioral surplus. Users are the human nature-al resource that provides this free raw material. Second, the application of machine learning, artificial intelligence, and data science for continuous algorithmic improvement constitutes an immensely expensive, sophisticated, and exclusive 21st century \u201cmeans of production.\u201d Third, the new manufacturing process converts behavioral surplus into prediction products designed to predict behavior now and soon. Fourth, these prediction products are sold into a new kind of meta-market that trades exclusively in future behavior. The better (more predictive) the product, the lower the risks for buyers, and the greater the volume of sales. Surveillance capitalism\u2019s profits derive primarily, if not entirely, from such markets for future behavior.</i> (via <a href=\"https://twitter.com/simonstl\">Simon St Laurent</a>)</li>\n",
        "<li><a href=\"http://thunder-project.org/\">Thunder</a> -- Spark-driven analysis from Jupyter notebooks (open source).</li>\n",
        "<li><a href=\"http://www.cse.msu.edu/rgroups/biometrics/Publications/Fingerprint/CaoJain_HackingMobilePhonesUsing2DPrintedFingerprint_MSU-CSE-16-2.pdf\">Hacking Mobile Phones Using 2D-Printed Fingerprints</a> (PDF) -- equipment costs less than $450, and all you need is a photo of the fingerprint. (like those of government employees <a href=\"http://www.defenseone.com/technology/2016/03/so-thumbprint-thing-your-phone-useless-now/126523/\">stolen en masse last year</a>)</li>\n",
        "<li><a href=\"https://github.com/Fachschaft07/SSHKeyDistribut0r\">SSHKeyDistribut0r</a> (Github) -- <i>A tool to automate key distribution with user authorization [...] for sysop teams.</i></li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=a72V_CKUuG0:hi5M1yLfMLE:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=a72V_CKUuG0:hi5M1yLfMLE:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=a72V_CKUuG0:hi5M1yLfMLE:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=a72V_CKUuG0:hi5M1yLfMLE:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=a72V_CKUuG0:hi5M1yLfMLE:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=a72V_CKUuG0:hi5M1yLfMLE:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=a72V_CKUuG0:hi5M1yLfMLE:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/a72V_CKUuG0\" width=\"1\" />\n",
        "Four short links: 8 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/cbcH4vSXON8/four-short-links-8-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://blog.acolyer.org/2016/03/08/cryptonets-applying-neural-networks-to-encrypted-data-with-high-throughput-and-accuracy/\">Neutral Nets on Encrypted Data</a> (Paper a Day) -- <i>By using a technique known as homohorphic encryption, it\u2019s possible to perform operations on encrypted data, producing an encrypted result, and then decrypt the result to give back the desired answer. By combining homohorphic encryption with a specially designed neural network that can operate within the constraints of the operations supported, the authors of CryptoNet are able to build an end-to-end system whereby a client can encrypt their data, send it to a cloud service that makes a prediction based on that data \u2013 all the while having no idea what the data means, or what the output prediction means \u2013 and return an encrypted prediction to the client, which can then decrypt it to recover the prediction. As well as making this possible, another significant challenge the authors had to overcome was making it practical, as homohorphic encryption can be expensive.</i></li>\n",
        "<li><a href=\"https://www.youtube.com/watch?v=Y7YyMK7r7a4\">VR for IoT Prototype</a> (YouTube) -- <i> a VR prototype created for displaying sensor data and video streaming in real time from IoT sensors/camera devices designed for rail or the transportation industry.</i></li>\n",
        "<li><a href=\"https://m.signalvnoise.com/is-group-chat-making-you-sweat-744659addf7d#.64avpu9sk\">Is Group Chat Making You Sweat?</a> (Jason Fried) -- all excellent points. Our attention and focus are the scarce and precious resources of the 21st century.</li>\n",
        "<li><a href=\"https://blog.somaticlabs.io/how-devices-provide-haptic-feedback/\">How Devices Provide Haptic Feedback</a> -- good intro to what's happening in your hardware.</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=cbcH4vSXON8:fT3KUMLuAXY:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=cbcH4vSXON8:fT3KUMLuAXY:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=cbcH4vSXON8:fT3KUMLuAXY:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=cbcH4vSXON8:fT3KUMLuAXY:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=cbcH4vSXON8:fT3KUMLuAXY:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=cbcH4vSXON8:fT3KUMLuAXY:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=cbcH4vSXON8:fT3KUMLuAXY:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/cbcH4vSXON8\" width=\"1\" />\n",
        "Four short links: 7 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/ZNMk_zUMRjo/four-short-links-7-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://blog.acolyer.org/2016/03/07/trajectory-data-mining-an-overview/\">Trajectory Data Mining: An Overview</a> (Paper a Day) -- <i>This is the data created by a moving object, as a sequence of locations, often with uncertainty around the exact location at each point. This could be GPS trajectories created by people or vehicles, spatial trajectories obtained via cell phone tower IDs and corresponding transmission times, the moving trajectories of animals (e.g. birds) fitted with trackers, or even data concerning natural phenomena such as hurricanes and ocean currents. It turns out, there\u2019s a lot to learn about working with such data!</i></li>\n",
        "<li><a href=\"http://www.pnas.org/content/112/33/E4512.full.pdf?with-ds=yes\">Search Engine Manipulation Effect</a> (PNAS) -- <i>Internet search rankings have a significant impact on consumer choices, mainly because users trust and choose higher-ranked results more than lower-ranked results. Given the apparent power of search rankings, we asked whether they could be manipulated to alter the preferences of undecided voters in democratic elections.</i> They could. Read the article for their methodology. (via <a href=\"https://aeon.co/essays/how-the-internet-flips-elections-and-alters-our-thoughts\">Aeon</a>)</li>\n",
        "<li><a href=\"http://keshif.me/\">Keshif</a> -- open source interactive data explorer.</li>\n",
        "<li><a href=\"http://proselint.com/\">proselint</a> -- analyse text for sins of usage and abusage.</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=ZNMk_zUMRjo:CvDXKNgfqZA:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=ZNMk_zUMRjo:CvDXKNgfqZA:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=ZNMk_zUMRjo:CvDXKNgfqZA:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=ZNMk_zUMRjo:CvDXKNgfqZA:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=ZNMk_zUMRjo:CvDXKNgfqZA:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=ZNMk_zUMRjo:CvDXKNgfqZA:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=ZNMk_zUMRjo:CvDXKNgfqZA:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/ZNMk_zUMRjo\" width=\"1\" />\n",
        "Four short links: 4 March 2016\n",
        "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/LaWTh4uAv1o/four-short-links-4-march-2016.html\n",
        "<ol>\n",
        "<li><a href=\"http://www.bloomberg.com/features/2016-how-snapchat-built-a-business/\">How Snapchat Built a Business by Confusing Olds</a> (Bloomberg) -- <i>Advertisers don\u2019t have a lot of good options to reach under-30s. The audiences of CBS, NBC, and ABC are, on average, in their 50s. Cable networks such as CNN and Fox News have it worse, with median viewerships near or past Social Security age. MTV\u2019s median viewers are in their early 20s, but ratings have dropped in recent years. Marketers are understandably anxious, and Spiegel and his deputies have capitalized on those anxieties brilliantly by charging hundreds of thousands of dollars when Snapchat introduces an ad product.</i></li>\n",
        "<li><a href=\"http://fusion.net/story/268108/dstillery-clever-tracking-trick/\">Tracking Voters</a> -- <i>On the night of the Iowa caucus, Dstillery flagged all the [ad network-mediated ad] auctions that took place on phones in latitudes and longitudes near caucus locations. It wound up spotting 16,000 devices on caucus night, as those people had granted location privileges to the apps or devices that served them ads. It captured those mobile ID\u2019s and then looked up the characteristics associated with those IDs in order to make observations about the kind of people that went to Republican caucus locations (young parents) versus Democrat caucus locations. It drilled down further (e.g., \u2018people who like NASCAR voted for Trump and Clinton\u2019) by looking at which candidate won at a particular caucus location.</i></li>\n",
        "<li><a href=\"http://arxiv.org/abs/1510.02377\">Discovering Unwarranted Associations in Data-Driven Applications with the FairTest Testing Toolkit</a> (arXiv) -- <i>We describe FairTest, a testing toolkit that detects unwarranted associations between an algorithm's outputs (e.g., prices or labels) and user subpopulations, including sensitive groups (e.g., defined by race or gender). FairTest reports statistically significant associations to programmers as association bugs, ranked by their strength and likelihood of being unintentional, rather than necessary effects.</i> See also <a href=\"http://www.cs.columbia.edu/~djhsu/papers/fairtest-privacycon.pdf\">slides from PrivacyCon</a>. Source code not yet released.</li>\n",
        "<li><a href=\"http://blog.acolyer.org/2016/03/03/inferring-causal-impact-using-bayesian-structural-time-series-models/\">Inferring Causal Impact Using Bayesian Structural Time-Series Models</a> (Adrian Colyer) -- understanding the impact of an intervention by building a predictive model of what would have happened without the intervention, then diffing reality to that model.</li>\n",
        "</ol>\n",
        "<div class=\"feedflare\">\n",
        "<a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=LaWTh4uAv1o:8eXfVg95qpo:V_sGLiPBpWU\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=LaWTh4uAv1o:8eXfVg95qpo:V_sGLiPBpWU\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=LaWTh4uAv1o:8eXfVg95qpo:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=LaWTh4uAv1o:8eXfVg95qpo:JEwB19i1-c4\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=LaWTh4uAv1o:8eXfVg95qpo:JEwB19i1-c4\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=LaWTh4uAv1o:8eXfVg95qpo:7Q72WNTAKBA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=LaWTh4uAv1o:8eXfVg95qpo:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs\" /></a>\n",
        "</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/LaWTh4uAv1o\" width=\"1\" />\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Scrapy\u57fa\u4e8epython\u7684\u7f51\u9875\u722c\u53d6\u6846\u67b6"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt = \"Mr. Green killed Colonel Mustard in the study with the candlestick. Mr. Green is not a very nice fellow.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1.\u53e5\u672b\u68c0\u6d4b\uff08EOS\u68c0\u6d4b\uff09"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "\n",
      "# Downloading nltk packages used in this example\n",
      "#http://nltk.github.com/nltk_data/\n",
      "#http://www.nltk.org/nltk_data/\n",
      "nltk.download('punkt') \n",
      "sentences = nltk.tokenize.sent_tokenize(txt)\n",
      "print sentences"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package punkt to E:\\nltk_data...\n",
        "[nltk_data]   Package punkt is already up-to-date!\n",
        "['Mr. Green killed Colonel Mustard in the study with the candlestick.', 'Mr. Green is not a very nice fellow.']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "2.\u5207\u8bcd\uff08**Tokenization of sentences**\uff09"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = [nltk.tokenize.word_tokenize(s) for s in sentences]\n",
      "print tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['Mr.', 'Green', 'killed', 'Colonel', 'Mustard', 'in', 'the', 'study', 'with', 'the', 'candlestick', '.'], ['Mr.', 'Green', 'is', 'not', 'a', 'very', 'nice', 'fellow', '.']]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "3.\u8bcd\u6027\u6807\u8bb0/POS\u6807\u8bb0\uff08**Part of speech tagging for tokens**\uff09"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Downloading nltk packages used in this example\n",
      "nltk.download('maxent_treebank_pos_tagger')\n",
      "\n",
      "pos_tagged_tokens = [nltk.pos_tag(t) for t in tokens]\n",
      "print pos_tagged_tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
        "[nltk_data]     E:\\nltk_data...\n",
        "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
        "[nltk_data]       date!\n"
       ]
      },
      {
       "ename": "URLError",
       "evalue": "<urlopen error unknown url type: e>",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-6-cb6e7e47be06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'maxent_treebank_pos_tagger'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpos_tagged_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mpos_tagged_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\tag\\__init__.pyc\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\tag\\perceptron.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\tag\\perceptron.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m    207\u001b[0m         '''\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\data.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\data.pyc\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;31m######################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         return self._call_chain(self.handle_open, 'unknown',\n\u001b[1;32m--> 454\u001b[1;33m                                 'unknown_open', req)\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36munknown_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0munknown_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unknown url type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparse_keqv_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mURLError\u001b[0m: <urlopen error unknown url type: e>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "4.\u5206\u5757"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "NLP CH9"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "5.\u63d0\u53d6**Named entity extraction/chunking for tokens**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Downloading nltk packages used in this example\n",
      "nltk.download('maxent_ne_chunker')\n",
      "nltk.download('words')\n",
      "\n",
      "ne_chunks = nltk.batch_ne_chunk(pos_tagged_tokens)\n",
      "print ne_chunks\n",
      "print ne_chunks[0].pprint() # You can prettyprint each chunk in the tree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example 4.\u901a\u8fc7\u89e3\u6790\u6e90\u6765\u83b7\u53d6\u535a\u5ba2\u6570\u636e"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import json\n",
      "import feedparser\n",
      "from bs4 import BeautifulSoup\n",
      "from nltk import clean_html\n",
      "\n",
      "FEED_URL = 'http://feeds.feedburner.com/oreilly/radar/atom'\n",
      " \n",
      "fp = feedparser.parse(FEED_URL)\n",
      "\n",
      "print \"Fetched %s entries from '%s'\" % (len(fp.entries[0].title), fp.feed.title)\n",
      "\n",
      "blog_posts = []\n",
      "for e in fp.entries:\n",
      "    soup = BeautifulSoup(e.content[0].value, 'html.parser') \n",
      "    blog_posts.append({'title': e.title, 'content'  : soup.get_text() , 'link': e.links[0].href})\n",
      "\n",
      "out_file = os.path.join('resources', 'ch05-webpages', 'feed.json')\n",
      "f = open(out_file, 'w')\n",
      "f.write(json.dumps(blog_posts, indent=1))\n",
      "f.close()\n",
      "\n",
      "print 'Wrote output file to %s' % (f.name, )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetched 31 entries from 'O'Reilly Radar - Insight, analysis, and research about emerging technologies'\n",
        "Wrote output file to resources\\ch05-webpages\\feed.json\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example 5. \u4f7f\u7528NLTK\u7684NLP\u5de5\u5177\u5904\u7406\u535a\u5ba2\u6570\u636e\u4e2d\u7684\u4eba\u7c7b\u8bed\u8a00"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import nltk\n",
      "\n",
      "# Download nltk packages used in this example\n",
      "nltk.download('stopwords')\n",
      "\n",
      "BLOG_DATA = \"resources/ch05-webpages/feed.json\"\n",
      "\n",
      "blog_data = json.loads(open(BLOG_DATA).read())\n",
      "\n",
      "# Customize your list of stopwords as needed. Here, we add common\n",
      "# punctuation and contraction artifacts.\n",
      "\n",
      "stop_words = nltk.corpus.stopwords.words('english') + [\n",
      "    '.',\n",
      "    ',',\n",
      "    '--',\n",
      "    '\\'s',\n",
      "    '?',\n",
      "    ')',\n",
      "    '(',\n",
      "    ':',\n",
      "    '\\'',\n",
      "    '\\'re',\n",
      "    '\"',\n",
      "    '-',\n",
      "    '}',\n",
      "    '{',\n",
      "    u'\u2014',\n",
      "    ]\n",
      "\n",
      "for post in blog_data:\n",
      "    sentences = nltk.tokenize.sent_tokenize(post['content'])\n",
      "\n",
      "    words = [w.lower() for sentence in sentences for w in\n",
      "             nltk.tokenize.word_tokenize(sentence)]\n",
      "\n",
      "    fdist = nltk.FreqDist(words)\n",
      "\n",
      "    # Basic stats\n",
      "\n",
      "    num_words = sum([i[1] for i in fdist.items()])\n",
      "    num_unique_words = len(fdist.keys())\n",
      "\n",
      "    # Hapaxes are words that appear only once\n",
      "\n",
      "    num_hapaxes = len(fdist.hapaxes())\n",
      "\n",
      "    top_10_words_sans_stop_words = [w for w in fdist.items() if w[0]\n",
      "                                    not in stop_words][:10]\n",
      "\n",
      "    print post['title']\n",
      "    print '\\tNum Sentences:'.ljust(25), len(sentences)\n",
      "    print '\\tNum Words:'.ljust(25), num_words\n",
      "    print '\\tNum Unique Words:'.ljust(25), num_unique_words\n",
      "    print '\\tNum Hapaxes:'.ljust(25), num_hapaxes\n",
      "    print '\\tTop 10 Most Frequent Words (sans stop words):\\n\\t\\t', \\\n",
      "            '\\n\\t\\t'.join(['%s (%s)'\n",
      "            % (w[0], w[1]) for w in top_10_words_sans_stop_words])\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package stopwords to\n",
        "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Unzipping corpora\\stopwords.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Four short links: 24 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tNum Sentences:           7\n",
        "\tNum Words:               103\n",
        "\tNum Unique Words:        70\n",
        "\tNum Hapaxes:             53\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\trating (2)\n",
        "\t\tfantastic (1)\n",
        "\t\tvia (1)\n",
        "\t\tangola (1)\n",
        "\t\tsequence (1)\n",
        "\t\tsimple (1)\n",
        "\t\tsite (1)\n",
        "\t\t'' (1)\n",
        "\t\tzero (2)\n",
        "\t\tservice (1)\n",
        "\n",
        "Four short links: 23 March 2016\n",
        "\tNum Sentences:           11\n",
        "\tNum Words:               290\n",
        "\tNum Unique Words:        176\n",
        "\tNum Hapaxes:             137\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\thelp (1)\n",
        "\t\trandom (1)\n",
        "\t\tthesis (1)\n",
        "\t\tquery (3)\n",
        "\t\tapproximators (1)\n",
        "\t\tissues (1)\n",
        "\t\tdeveloper (1)\n",
        "\t\tnote (1)\n",
        "\t\tlayout (1)\n",
        "\t\tthinking (1)\n",
        "\n",
        "Four short links: 22 March 2016\n",
        "\tNum Sentences:           15\n",
        "\tNum Words:               388\n",
        "\tNum Unique Words:        231\n",
        "\tNum Hapaxes:             184\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\tbldgblog (1)\n",
        "\t\tphoto (1)\n",
        "\t\tthresholds (1)\n",
        "\t\tdeployment (1)\n",
        "\t\tyears (1)\n",
        "\t\tburglary (3)\n",
        "\t\tpaper (1)\n",
        "\t\thuman (1)\n",
        "\t\tcurrent (2)\n",
        "\t\tcut (1)\n",
        "\n",
        "Four short links: 21 March 2016\n",
        "\tNum Sentences:           12\n",
        "\tNum Words:               190\n",
        "\tNum Unique Words:        127\n",
        "\tNum Hapaxes:             103\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\ttext (1)\n",
        "\t\tmagnetic (1)\n",
        "\t\t`` (2)\n",
        "\t\tspanking (1)\n",
        "\t\tyears (1)\n",
        "\t\thuman (2)\n",
        "\t\tusing (1)\n",
        "\t\tnets (1)\n",
        "\t\tyet (1)\n",
        "\t\titp (1)\n",
        "\n",
        "Four short links: 18 March 2016\n",
        "\tNum Sentences:           6\n",
        "\tNum Words:               215\n",
        "\tNum Unique Words:        134\n",
        "\tNum Hapaxes:             109\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\thaven\u2019t (1)\n",
        "\t\tsigbovik (1)\n",
        "\t\tendofunctor (1)\n",
        "\t\texecutive (2)\n",
        "\t\tsouls (1)\n",
        "\t\tjihad (1)\n",
        "\t\ttalks (1)\n",
        "\t\tmayor (1)\n",
        "\t\twriting (1)\n",
        "\t\tdisgust (1)\n",
        "\n",
        "Four short links: 17 March 2016\n",
        "\tNum Sentences:           8\n",
        "\tNum Words:               189\n",
        "\tNum Unique Words:        119\n",
        "\tNum Hapaxes:             92\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\tnlp (2)\n",
        "\t\thelp (1)\n",
        "\t\tholman (1)\n",
        "\t\tdeveloped (1)\n",
        "\t\tyears (1)\n",
        "\t\tscientist (1)\n",
        "\t\tidentify (1)\n",
        "\t\ttweet (1)\n",
        "\t\tprogram (1)\n",
        "\t\ttweets (3)\n",
        "\n",
        "Four short links: 16 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tNum Sentences:           22\n",
        "\tNum Words:               479\n",
        "\tNum Unique Words:        249\n",
        "\tNum Hapaxes:             177\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\tcode (2)\n",
        "\t\tunfolds (1)\n",
        "\t\thelp (1)\n",
        "\t\ttext (1)\n",
        "\t\tabilities (1)\n",
        "\t\tpaper (4)\n",
        "\t\tnyt (1)\n",
        "\t\tpredicts (1)\n",
        "\t\ttend (1)\n",
        "\t\tchildren (3)\n",
        "\n",
        "Four short links: 15 March 2016\n",
        "\tNum Sentences:           9\n",
        "\tNum Words:               207\n",
        "\tNum Unique Words:        139\n",
        "\tNum Hapaxes:             113\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\tconsider (1)\n",
        "\t\tglobal (1)\n",
        "\t\tjapan (1)\n",
        "\t\tgroup (1)\n",
        "\t\talso (1)\n",
        "\t\tsource (1)\n",
        "\t\tsystems (2)\n",
        "\t\t2016 (1)\n",
        "\t\tfda (2)\n",
        "\t\tseeking (1)\n",
        "\n",
        "Four short links: 14 March 2016\n",
        "\tNum Sentences:           9\n",
        "\tNum Words:               298\n",
        "\tNum Unique Words:        193\n",
        "\tNum Hapaxes:             156\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\tito (1)\n",
        "\t\tthomas (1)\n",
        "\t\ttagged (1)\n",
        "\t\tless (1)\n",
        "\t\tglobal (1)\n",
        "\t\t$ (1)\n",
        "\t\tattitude (1)\n",
        "\t\tpaper (1)\n",
        "\t\taspect (1)\n",
        "\t\tamplified (1)\n",
        "\n",
        "Four short links: 11 March 2016\n",
        "\tNum Sentences:           7\n",
        "\tNum Words:               156\n",
        "\tNum Unique Words:        106\n",
        "\tNum Hapaxes:             78\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\tspeed (1)\n",
        "\t\tincrease (1)\n",
        "\t\tpersonal (1)\n",
        "\t\tdevice (1)\n",
        "\t\tregularly (1)\n",
        "\t\tmaterial (1)\n",
        "\t\tmatters (1)\n",
        "\t\tamazon (1)\n",
        "\t\tbit (1)\n",
        "\t\techo (2)\n",
        "\n",
        "Four short links: 10 March 2016\n",
        "\tNum Sentences:           19\n",
        "\tNum Words:               510\n",
        "\tNum Unique Words:        281\n",
        "\tNum Hapaxes:             204\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\ttwitter\u2019s (1)\n",
        "\t\ta/b (2)\n",
        "\t\tlearning (2)\n",
        "\t\tconsider (1)\n",
        "\t\tshow (1)\n",
        "\t\tcaptures (1)\n",
        "\t\tfind (1)\n",
        "\t\tchoose (1)\n",
        "\t\texisting (1)\n",
        "\t\tbrain (1)\n",
        "\n",
        "Four short links: 9 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tNum Sentences:           10\n",
        "\tNum Words:               269\n",
        "\tNum Unique Words:        169\n",
        "\tNum Hapaxes:             138\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\texclusive (1)\n",
        "\t\tconcept (1)\n",
        "\t\tsurplus (2)\n",
        "\t\tless (1)\n",
        "\t\tsales (1)\n",
        "\t\tphoto (1)\n",
        "\t\tsoon (1)\n",
        "\t\tspaces (1)\n",
        "\t\tcircumscribed (1)\n",
        "\t\t2d-printed (1)\n",
        "\n",
        "Four short links: 8 March 2016\n",
        "\tNum Sentences:           8\n",
        "\tNum Words:               246\n",
        "\tNum Unique Words:        139\n",
        "\tNum Hapaxes:             96\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\toperations (2)\n",
        "\t\tjason (1)\n",
        "\t\tfeedback (1)\n",
        "\t\tencrypted (4)\n",
        "\t\tsupported (1)\n",
        "\t\tfocus (1)\n",
        "\t\tpaper (1)\n",
        "\t\tscarce (1)\n",
        "\t\tnets (1)\n",
        "\t\t21st (1)\n",
        "\n",
        "Four short links: 7 March 2016\n",
        "\tNum Sentences:           10\n",
        "\tNum Words:               196\n",
        "\tNum Unique Words:        130\n",
        "\tNum Hapaxes:             102\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\ttext (1)\n",
        "\t\thigher-ranked (1)\n",
        "\t\tmainly (1)\n",
        "\t\tchoose (1)\n",
        "\t\tpaper (1)\n",
        "\t\tbirds (1)\n",
        "\t\timpact (1)\n",
        "\t\tlocation (1)\n",
        "\t\tusage (1)\n",
        "\t\talter (1)\n",
        "\n",
        "Four short links: 4 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tNum Sentences:           14\n",
        "\tNum Words:               374\n",
        "\tNum Unique Words:        224\n",
        "\tNum Hapaxes:             179\n",
        "\tTop 10 Most Frequent Words (sans stop words):\n",
        "\t\tsubpopulations (1)\n",
        "\t\tcode (1)\n",
        "\t\tdata-driven (1)\n",
        "\t\twound (1)\n",
        "\t\tlabels (1)\n",
        "\t\tyears (1)\n",
        "\t\tbayesian (1)\n",
        "\t\tincluding (1)\n",
        "\t\tprivacycon (1)\n",
        "\t\tnetworks (1)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example 6.\u57fa\u4e8e\u53e5\u5b50\u68c0\u6d4b\u548c\u53e5\u4e2d\u9891\u7387\u5206\u6790\u7684\u6587\u6863\u6458\u8981\u7b97\u6cd5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import nltk\n",
      "import numpy\n",
      "\n",
      "BLOG_DATA = \"resources/ch05-webpages/feed.json\"\n",
      "\n",
      "N = 100  # Number of words to consider\n",
      "CLUSTER_THRESHOLD = 5  # Distance between words to consider\n",
      "TOP_SENTENCES = 5  # Number of sentences to return for a \"top n\" summary\n",
      "\n",
      "# Approach taken from \"The Automatic Creation of Literature Abstracts\" by H.P. Luhn\n",
      "\n",
      "def _score_sentences(sentences, important_words):\n",
      "    scores = []\n",
      "    sentence_idx = -1\n",
      "\n",
      "    for s in [nltk.tokenize.word_tokenize(s) for s in sentences]:\n",
      "\n",
      "        sentence_idx += 1\n",
      "        word_idx = []\n",
      "\n",
      "        # For each word in the word list...\n",
      "        for w in important_words:\n",
      "            try:\n",
      "                # Compute an index for where any important words occur in the sentence.\n",
      "\n",
      "                word_idx.append(s.index(w))\n",
      "            except ValueError, e: # w not in this particular sentence\n",
      "                pass\n",
      "\n",
      "        word_idx.sort()\n",
      "\n",
      "        # It is possible that some sentences may not contain any important words at all.\n",
      "        if len(word_idx)== 0: continue\n",
      "\n",
      "        # Using the word index, compute clusters by using a max distance threshold\n",
      "        # for any two consecutive words.\n",
      "\n",
      "        clusters = []\n",
      "        cluster = [word_idx[0]]\n",
      "        i = 1\n",
      "        while i < len(word_idx):\n",
      "            if word_idx[i] - word_idx[i - 1] < CLUSTER_THRESHOLD:\n",
      "                cluster.append(word_idx[i])\n",
      "            else:\n",
      "                clusters.append(cluster[:])\n",
      "                cluster = [word_idx[i]]\n",
      "            i += 1\n",
      "        clusters.append(cluster)\n",
      "\n",
      "        # Score each cluster. The max score for any given cluster is the score \n",
      "        # for the sentence.\n",
      "\n",
      "        max_cluster_score = 0\n",
      "        for c in clusters:\n",
      "            significant_words_in_cluster = len(c)\n",
      "            total_words_in_cluster = c[-1] - c[0] + 1\n",
      "            score = 1.0 * significant_words_in_cluster \\\n",
      "                * significant_words_in_cluster / total_words_in_cluster\n",
      "\n",
      "            if score > max_cluster_score:\n",
      "                max_cluster_score = score\n",
      "\n",
      "        scores.append((sentence_idx, score))\n",
      "\n",
      "    return scores\n",
      "\n",
      "def summarize(txt):\n",
      "    sentences = [s for s in nltk.tokenize.sent_tokenize(txt)]\n",
      "    normalized_sentences = [s.lower() for s in sentences]\n",
      "\n",
      "    words = [w.lower() for sentence in normalized_sentences for w in\n",
      "             nltk.tokenize.word_tokenize(sentence)]\n",
      "\n",
      "    fdist = nltk.FreqDist(words)\n",
      "\n",
      "    top_n_words = [w[0] for w in fdist.items() \n",
      "            if w[0] not in nltk.corpus.stopwords.words('english')][:N]\n",
      "\n",
      "    scored_sentences = _score_sentences(normalized_sentences, top_n_words)\n",
      "\n",
      "    # Summarization Approach 1:\n",
      "    # Filter out nonsignificant sentences by using the average score plus a\n",
      "    # fraction of the std dev as a filter\n",
      "\n",
      "    avg = numpy.mean([s[1] for s in scored_sentences])\n",
      "    std = numpy.std([s[1] for s in scored_sentences])\n",
      "    mean_scored = [(sent_idx, score) for (sent_idx, score) in scored_sentences\n",
      "                   if score > avg + 0.5 * std]\n",
      "\n",
      "    # Summarization Approach 2:\n",
      "    # Another approach would be to return only the top N ranked sentences\n",
      "\n",
      "    top_n_scored = sorted(scored_sentences, key=lambda s: s[1])[-TOP_SENTENCES:]\n",
      "    top_n_scored = sorted(top_n_scored, key=lambda s: s[0])\n",
      "\n",
      "    # Decorate the post object with summaries\n",
      "\n",
      "    return dict(top_n_summary=[sentences[idx] for (idx, score) in top_n_scored],\n",
      "                mean_scored_summary=[sentences[idx] for (idx, score) in mean_scored])\n",
      "\n",
      "blog_data = json.loads(open(BLOG_DATA).read())\n",
      "\n",
      "for post in blog_data:\n",
      "       \n",
      "    post.update(summarize(post['content']))\n",
      "\n",
      "    print post['title']\n",
      "    print '=' * len(post['title'])\n",
      "    print\n",
      "    print 'Top N Summary'\n",
      "    print '-------------'\n",
      "    print ' '.join(post['top_n_summary'])\n",
      "    print\n",
      "    print 'Mean Scored Summary'\n",
      "    print '-------------------'\n",
      "    print ' '.join(post['mean_scored_summary'])\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Four short links: 24 March 2016\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "\n",
        "Maintain Separate Github Accounts -- simple advice. Zero Rating's Problem -- Wikipedia was zero-rated for Angola, so Angolans began swapping movies via Wikipedia. Zero rating (\"no data charge for this service\") is an incentive to use the site, not necessarily for the purpose intended. Motion Design is the Future of UI -- Motion tells stories. Someone caught the animations and transitions bug.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "Zero Rating's Problem -- Wikipedia was zero-rated for Angola, so Angolans began swapping movies via Wikipedia. Zero rating (\"no data charge for this service\") is an incentive to use the site, not necessarily for the purpose intended.\n",
        "\n",
        "Four short links: 23 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "But every developer should be forced to write 100 times: \"if you build on a platform you don't own, you're building on a potential and probable future competitor.\" Traditional Economics Failed, Here's a Blueprint -- runs through the shifts happening in our thinking about the world and ourselves (simple to complex, independent to interdependent, rational calculator to irrational approximators, etc) and concludes: True self-interest is mutual interest. Blitzscaling (HBR) -- as you move from village to city, functions are beginning to be differentiated; you\u2019re really multithreading. I could write a thesis on the CAP theorem for business. And I have definitely worked for companies that have a \"share nothing\" approach to solving their threading issues.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "But every developer should be forced to write 100 times: \"if you build on a platform you don't own, you're building on a potential and probable future competitor.\" Traditional Economics Failed, Here's a Blueprint -- runs through the shifts happening in our thinking about the world and ourselves (simple to complex, independent to interdependent, rational calculator to irrational approximators, etc) and concludes: True self-interest is mutual interest. Blitzscaling (HBR) -- as you move from village to city, functions are beginning to be differentiated; you\u2019re really multithreading.\n",
        "\n",
        "Four short links: 22 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "Without buildings, burglary, in its current legal form, could not exist. In fact, one needn\u2019t steal anything at all to be a burglar. Connection to computer security left as exercise to the reader. Report includes recommendations for policy makers. (via Dan Hill)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "Without buildings, burglary, in its current legal form, could not exist. In fact, one needn\u2019t steal anything at all to be a burglar. Connection to computer security left as exercise to the reader. Report includes recommendations for policy makers. (via Dan Hill)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Four short links: 21 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "Age and Gender Classification Using Convolutional Neural Nets -- oh, this will end well. The Uncanny Valley of Words (Ross Goodwin) -- lessons learned from an NYU ITP neural networker making poetry and surprises from text. The Paradox of Human Performance (YouTube) -- Human dexterity and agility vastly exceed that of contemporary robots. Yet, humans have vastly slower \"hardware\" (e.g. Slow actuators and long communication delays require predictive control based on some form of internal model\u2014but what form?\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "Age and Gender Classification Using Convolutional Neural Nets -- oh, this will end well. The Uncanny Valley of Words (Ross Goodwin) -- lessons learned from an NYU ITP neural networker making poetry and surprises from text. The Paradox of Human Performance (YouTube) -- Human dexterity and agility vastly exceed that of contemporary robots. Slow actuators and long communication delays require predictive control based on some form of internal model\u2014but what form?\n",
        "\n",
        "Four short links: 18 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "\n",
        "Engineers of Jihad (Marginal Revolution) -- brief book review, tantalizing. The distribution of traits across disciplines mirrors almost exactly the distribution of disciplines across militant groups\u2026engineers are present in groups in which social scientists, humanities graduates, and women are absent, and engineers possess traits \u2014 proneness to disgust, need for closure, in-group bias, and (at least tentatively) simplism\u2026\n",
        "Box of a Trillion Souls -- review and critique of some of Stephen Wolfram's writing and speaking about AI and simulation and the nature of reality and complexity and ... a lot. Alphabet Starting Sidewalk Labs (NY Times) -- \u201cWe\u2019re taking everything from anonymized smartphone data from billions of miles of trips, sensor data, and bringing that into a platform that will give both the public and private parties and government the capacity to actually understand the data in ways they haven\u2019t before,\u201d said Daniel L. Doctoroff, Sidewalk\u2019s chief executive, who is a former deputy mayor of New York City and former chief executive of Bloomberg. SIGBOVIK -- the proceedings from 2015 include a paper that talks about \"The Tortilla Endofunctor.\" You're welcome.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "The distribution of traits across disciplines mirrors almost exactly the distribution of disciplines across militant groups\u2026engineers are present in groups in which social scientists, humanities graduates, and women are absent, and engineers possess traits \u2014 proneness to disgust, need for closure, in-group bias, and (at least tentatively) simplism\u2026\n",
        "Box of a Trillion Souls -- review and critique of some of Stephen Wolfram's writing and speaking about AI and simulation and the nature of reality and complexity and ... a lot.\n",
        "\n",
        "Four short links: 17 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "\n",
        "Algorithm Identifies Tweets Sent Under the Influence of Alcohol (MIT TR) -- notable for how they determined whether a Tweet was sent from home. They made a list of phrases like \"home at last!\" Puzzle Game to Help Program Quantum Computers (New Scientist) -- Devitt has turned the problem of programming a quantum computer into a game called meQuanics. His team has developed a prototype to test the game, which you can play now, and today launched a Kickstarter campaign to fund a fully fledged version for iOS and Android phones. Deep or Shallow, NLP is Breaking Out (ACM) -- readable roundup of how NLP changed in the last five years, with a useful list for further reading and watching.\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "\n",
        "Algorithm Identifies Tweets Sent Under the Influence of Alcohol (MIT TR) -- notable for how they determined whether a Tweet was sent from home. Puzzle Game to Help Program Quantum Computers (New Scientist) -- Devitt has turned the problem of programming a quantum computer into a game called meQuanics. His team has developed a prototype to test the game, which you can play now, and today launched a Kickstarter campaign to fund a fully fledged version for iOS and Android phones. Deep or Shallow, NLP is Breaking Out (ACM) -- readable roundup of how NLP changed in the last five years, with a useful list for further reading and watching.\n",
        "\n",
        "Four short links: 16 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "The authors propose the mechanism is that empathetic children pick up a teacher's own dislike of math, and any teacher biases like \"girls aren't good at math.\" Sixty percent of books fell into a range where 25% to 50% of test readers finished them. Fat paper stock and 14-point text with wide margins and 1.5 line spacing help, too. Don't forget to leave pages after each chapter for the reader's notes. And ... sorry, I need to take a moment.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "\u201cThat\u2019s what research is all about!\u201d you may say, but it\u2019s also what we\u2019d (I\u2019d?) The authors propose the mechanism is that empathetic children pick up a teacher's own dislike of math, and any teacher biases like \"girls aren't good at math.\" Sixty percent of books fell into a range where 25% to 50% of test readers finished them. Fat paper stock and 14-point text with wide margins and 1.5 line spacing help, too. Don't forget to leave pages after each chapter for the reader's notes. And ... sorry, I need to take a moment.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Four short links: 15 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "\n",
        "The 2016 Car Hacker's Handbook (Amazon) -- will give you a deeper understanding of the computer systems and embedded software in modern vehicles. It begins by examining vulnerabilities and providing detailed explanations of communications over the CAN bus and between devices and systems. (via BoingBoing)\n",
        "More Exoskeletons Seeking FDA Approval -- The international group of exoskeleton providers with various FDA or CE certifications is growing and currently includes: Ekso in the US; Cyberdyne in the EU and Japan; ExoAtlet from Russia; and Israel\u2019s ReWalk. Dirigible Spreadsheet -- open source spreadsheet that's not just written in Python, it exposes and IS python. I'm not ready to consider all of these \"busted,\" but they are some nice starters-for-ten in your next pub argument about whether the Matrix is coming.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "\n",
        "The 2016 Car Hacker's Handbook (Amazon) -- will give you a deeper understanding of the computer systems and embedded software in modern vehicles. (via BoingBoing)\n",
        "More Exoskeletons Seeking FDA Approval -- The international group of exoskeleton providers with various FDA or CE certifications is growing and currently includes: Ekso in the US; Cyberdyne in the EU and Japan; ExoAtlet from Russia; and Israel\u2019s ReWalk.\n",
        "\n",
        "Four short links: 14 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "\n",
        "What Thomas Hardy Taught Me -- In educational research, perhaps the greatest danger lies in thinking \u201cthat which I cannot measure is not real.\u201d The disruption fetishists have amplified this danger, now evincing the attitude \u201cteaching that cannot be said to lead to the immediate acquisition of rote, mechanical skills has no value.\u201d But absolutely every aspect of my educational journey \u2014 as a student, as a teacher, and as a researcher \u2014 demonstrates the folly of this approach to learning. The conversation on creating new AML and KYC laws for new financial systems like bitcoin and blockchain needs to be a global one. Secrets, Lies, and Account Recovery: Lessons from the Use of Personal Knowledge Questions at Google -- Adrian Colyer summarizes a paper from Google. This took less than a day and cost $100. Clever MEMS 3D Object Tracking -- early Oculus engineer has invented a nifty way to track a tagged object in 3D space.\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "Secrets, Lies, and Account Recovery: Lessons from the Use of Personal Knowledge Questions at Google -- Adrian Colyer summarizes a paper from Google. Clever MEMS 3D Object Tracking -- early Oculus engineer has invented a nifty way to track a tagged object in 3D space.\n",
        "\n",
        "Four short links: 11 March 2016\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "\n",
        "Strategic Dialogue Management via Deep Reinforcement Learning (Adrian Colyer) -- a neural network learns to play Settlers of Catan. scala school -- Twitter's instructional material for coming up to speed on scala. Robin Hood Fellowship -- fellowship to use technology to increase access to legal services for New Yorkers. The Echo From Amazon Brims With Groundbreaking Promise (NY Times) -- A bit more than a year after its release, the Echo has morphed from a gimmicky experiment into a device that brims with profound possibility. The longer I use it, the more regularly it inspires the same sense of promise I felt when I used the first iPhone \u2014 a sense this machine is opening up a vast new realm in personal computing, and gently expanding the role that computers will play in our future.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "\n",
        "Strategic Dialogue Management via Deep Reinforcement Learning (Adrian Colyer) -- a neural network learns to play Settlers of Catan. The Echo From Amazon Brims With Groundbreaking Promise (NY Times) -- A bit more than a year after its release, the Echo has morphed from a gimmicky experiment into a device that brims with profound possibility. The longer I use it, the more regularly it inspires the same sense of promise I felt when I used the first iPhone \u2014 a sense this machine is opening up a vast new realm in personal computing, and gently expanding the role that computers will play in our future.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Four short links: 10 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "===============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "Deep learning systems like the one built by Hill and his colleagues reflect a cognitivist approach, but for a system to have something approaching human intelligence, it would have to have a little of both. \u201cOur system can\u2019t go too far beyond the dictionary data on which it was trained, but the ways in which it can are interesting, and make it a surprisingly robust question and answer system \u2013 and quite good at solving crossword puzzles,\u201d said Hill. Some examples are making budgets, assigning water resources, and setting tax rates. prove that asking users to compare projects in terms of \u201cvalue for money\u201d or asking them to choose an entire budget results in provably better properties than using the more traditional approaches of approval or rank-choice voting. Power, Minimal Detectable Effect, and Bucket Size Estimation in A/B Tests (Twitter) -- This post describes how Twitter\u2019s A/B testing framework, DDG, addresses one of the most common questions we hear from experimenters, product managers, and engineers: how many users do we need to sample in order to run an informative experiment?\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "Deep learning systems like the one built by Hill and his colleagues reflect a cognitivist approach, but for a system to have something approaching human intelligence, it would have to have a little of both. \u201cOur system can\u2019t go too far beyond the dictionary data on which it was trained, but the ways in which it can are interesting, and make it a surprisingly robust question and answer system \u2013 and quite good at solving crossword puzzles,\u201d said Hill. Some examples are making budgets, assigning water resources, and setting tax rates. prove that asking users to compare projects in terms of \u201cvalue for money\u201d or asking them to choose an entire budget results in provably better properties than using the more traditional approaches of approval or rank-choice voting. Power, Minimal Detectable Effect, and Bucket Size Estimation in A/B Tests (Twitter) -- This post describes how Twitter\u2019s A/B testing framework, DDG, addresses one of the most common questions we hear from experimenters, product managers, and engineers: how many users do we need to sample in order to run an informative experiment?\n",
        "\n",
        "Four short links: 9 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "==============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "Users are the human nature-al resource that provides this free raw material. Fourth, these prediction products are sold into a new kind of meta-market that trades exclusively in future behavior. The better (more predictive) the product, the lower the risks for buyers, and the greater the volume of sales. (via Simon St Laurent)\n",
        "Thunder -- Spark-driven analysis from Jupyter notebooks (open source). (like those of government employees stolen en masse last year)\n",
        "SSHKeyDistribut0r (Github) -- A tool to automate key distribution with user authorization [...] for sysop teams.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "(via Simon St Laurent)\n",
        "Thunder -- Spark-driven analysis from Jupyter notebooks (open source). (like those of government employees stolen en masse last year)\n",
        "SSHKeyDistribut0r (Github) -- A tool to automate key distribution with user authorization [...] for sysop teams.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Four short links: 8 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "==============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "As well as making this possible, another significant challenge the authors had to overcome was making it practical, as homohorphic encryption can be expensive. VR for IoT Prototype (YouTube) --  a VR prototype created for displaying sensor data and video streaming in real time from IoT sensors/camera devices designed for rail or the transportation industry. (Jason Fried) -- all excellent points. Our attention and focus are the scarce and precious resources of the 21st century. How Devices Provide Haptic Feedback -- good intro to what's happening in your hardware.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "VR for IoT Prototype (YouTube) --  a VR prototype created for displaying sensor data and video streaming in real time from IoT sensors/camera devices designed for rail or the transportation industry. How Devices Provide Haptic Feedback -- good intro to what's happening in your hardware.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "Four short links: 7 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "==============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "This could be GPS trajectories created by people or vehicles, spatial trajectories obtained via cell phone tower IDs and corresponding transmission times, the moving trajectories of animals (e.g. birds) fitted with trackers, or even data concerning natural phenomena such as hurricanes and ocean currents. Search Engine Manipulation Effect (PNAS) -- Internet search rankings have a significant impact on consumer choices, mainly because users trust and choose higher-ranked results more than lower-ranked results. Given the apparent power of search rankings, we asked whether they could be manipulated to alter the preferences of undecided voters in democratic elections. (via Aeon)\n",
        "Keshif -- open source interactive data explorer.\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "This could be GPS trajectories created by people or vehicles, spatial trajectories obtained via cell phone tower IDs and corresponding transmission times, the moving trajectories of animals (e.g. Search Engine Manipulation Effect (PNAS) -- Internet search rankings have a significant impact on consumer choices, mainly because users trust and choose higher-ranked results more than lower-ranked results. Given the apparent power of search rankings, we asked whether they could be manipulated to alter the preferences of undecided voters in democratic elections. (via Aeon)\n",
        "Keshif -- open source interactive data explorer.\n",
        "\n",
        "Four short links: 4 March 2016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "==============================\n",
        "\n",
        "Top N Summary\n",
        "-------------\n",
        "\n",
        "How Snapchat Built a Business by Confusing Olds (Bloomberg) -- Advertisers don\u2019t have a lot of good options to reach under-30s. Cable networks such as CNN and Fox News have it worse, with median viewerships near or past Social Security age. Marketers are understandably anxious, and Spiegel and his deputies have capitalized on those anxieties brilliantly by charging hundreds of thousands of dollars when Snapchat introduces an ad product. Tracking Voters -- On the night of the Iowa caucus, Dstillery flagged all the [ad network-mediated ad] auctions that took place on phones in latitudes and longitudes near caucus locations. It captured those mobile ID\u2019s and then looked up the characteristics associated with those IDs in order to make observations about the kind of people that went to Republican caucus locations (young parents) versus Democrat caucus locations.\n",
        "\n",
        "Mean Scored Summary\n",
        "-------------------\n",
        "Cable networks such as CNN and Fox News have it worse, with median viewerships near or past Social Security age. Tracking Voters -- On the night of the Iowa caucus, Dstillery flagged all the [ad network-mediated ad] auctions that took place on phones in latitudes and longitudes near caucus locations. It captured those mobile ID\u2019s and then looked up the characteristics associated with those IDs in order to make observations about the kind of people that went to Republican caucus locations (young parents) versus Democrat caucus locations.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example 7. \u7528HTML\u8f93\u51fa\u5c06\u6587\u6863\u6458\u8981\u7ed3\u679c\u53ef\u89c6\u5316"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\u6458\u8981\u7b97\u6cd5\u786e\u5b9a\u7684\u91cd\u70b9\u53e5\u5b50\u7531\u7c97\u4f53\u5b57\u8868\u793a"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import json\n",
      "import nltk\n",
      "import numpy\n",
      "from IPython.display import IFrame\n",
      "from IPython.core.display import display\n",
      "\n",
      "BLOG_DATA = \"resources/ch05-webpages/feed.json\"\n",
      "\n",
      "HTML_TEMPLATE = \"\"\"<html>\n",
      "    <head>\n",
      "        <title>%s</title>\n",
      "        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>\n",
      "    </head>\n",
      "    <h1>%s</h1>\n",
      "    <body>%s</body>\n",
      "</html>\"\"\"\n",
      "\n",
      "blog_data = json.loads(open(BLOG_DATA).read())\n",
      "\n",
      "for post in blog_data: \n",
      "    # Uses previously defined summarize function.\n",
      "    post.update(summarize(post['content']))\n",
      "\n",
      "    # You could also store a version of the full post with key sentences marked up\n",
      "    # for analysis with simple string replacement...\n",
      "\n",
      "    for summary_type in ['top_n_summary', 'mean_scored_summary']:\n",
      "        post[summary_type + '_marked_up'] = '<p>%s</p>' % (post['content'], )\n",
      "        for s in post[summary_type]:\n",
      "            post[summary_type + '_marked_up'] = post[summary_type + '_marked_up'].replace(s, '<strong>%s</strong>' % (s,))\n",
      "\n",
      "        filename = post['title'].replace(\"?\", \"\") + '.summary.' + summary_type + '.html'\n",
      "        f = open(os.path.join('resources','ch05-webpages',filename), 'w')        \n",
      "        html = HTML_TEMPLATE % (post['title'] +  ' Summary',post['title'] , post[summary_type + '_marked_up'],)\n",
      "              \n",
      "        f.write(html.encode('utf-8'))\n",
      "        f.close()\n",
      "\n",
      "        #print \"Data written to\", f.name\n",
      "\n",
      "# Display any of these files with an inline frame. This displays the\n",
      "# last file processed by using the last value of f.name...\n",
      "\n",
      "#print \"Displaying %s:\" % f.name\n",
      "display(IFrame('files/%s' % f.name, '100%', '600px'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "        <iframe\n",
        "            width=\"100%\"\n",
        "            height=600px\"\n",
        "            src=\"files/resources\\ch05-webpages\\Four short links: 4 March 2016.summary.mean_scored_summary.html\"\n",
        "            frameborder=\"0\"\n",
        "            allowfullscreen\n",
        "        ></iframe>\n",
        "        "
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.lib.display.IFrame at 0xdbc9450>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example 8. \u4f7f\u7528NLTK\u4ece\u6587\u672c\u4e2d\u62bd\u53d6\u5b9e\u4f53"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import json\n",
      "\n",
      "BLOG_DATA = \"resources/ch05-webpages/feed.json\"\n",
      "\n",
      "blog_data = json.loads(open(BLOG_DATA).read())\n",
      "\n",
      "for post in blog_data:\n",
      "\n",
      "    sentences = nltk.tokenize.sent_tokenize(post['content'])\n",
      "    tokens = [nltk.tokenize.word_tokenize(s) for s in sentences]\n",
      "    pos_tagged_tokens = [nltk.pos_tag(t) for t in tokens]\n",
      "\n",
      "    # Flatten the list since we're not using sentence structure\n",
      "    # and sentences are guaranteed to be separated by a special\n",
      "    # POS tuple such as ('.', '.')\n",
      "\n",
      "    pos_tagged_tokens = [token for sent in pos_tagged_tokens for token in sent]\n",
      "\n",
      "    all_entity_chunks = []\n",
      "    previous_pos = None\n",
      "    current_entity_chunk = []\n",
      "    for (token, pos) in pos_tagged_tokens:\n",
      "\n",
      "        if pos == previous_pos and pos.startswith('NN'):\n",
      "            current_entity_chunk.append(token)\n",
      "        elif pos.startswith('NN'):\n",
      "            if current_entity_chunk != []:\n",
      "\n",
      "                # Note that current_entity_chunk could be a duplicate when appended,\n",
      "                # so frequency analysis again becomes a consideration\n",
      "\n",
      "                all_entity_chunks.append((' '.join(current_entity_chunk), pos))\n",
      "            current_entity_chunk = [token]\n",
      "\n",
      "        previous_pos = pos\n",
      "\n",
      "    # Store the chunks as an index for the document\n",
      "    # and account for frequency while we're at it...\n",
      "\n",
      "    post['entities'] = {}\n",
      "    for c in all_entity_chunks:\n",
      "        post['entities'][c] = post['entities'].get(c, 0) + 1\n",
      "\n",
      "    # For example, we could display just the title-cased entities\n",
      "\n",
      "    print post['title']\n",
      "    print '-' * len(post['title'])\n",
      "    proper_nouns = []\n",
      "    for (entity, pos) in post['entities']:\n",
      "        if entity.istitle():\n",
      "            print '\\t%s (%s)' % (entity, post['entities'][(entity, pos)])\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "URLError",
       "evalue": "<urlopen error unknown url type: e>",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-1772723df594>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mpos_tagged_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Flatten the list since we're not using sentence structure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\tag\\__init__.pyc\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\tag\\perceptron.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\tag\\perceptron.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m    207\u001b[0m         '''\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\data.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\data.pyc\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;31m######################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         return self._call_chain(self.handle_open, 'unknown',\n\u001b[1;32m--> 454\u001b[1;33m                                 'unknown_open', req)\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36munknown_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0munknown_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unknown url type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparse_keqv_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mURLError\u001b[0m: <urlopen error unknown url type: e>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example 9. \u63a2\u7d22\u5b9e\u4f53\u95f4\u7684\u4ea4\u4e92"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import json\n",
      "\n",
      "BLOG_DATA = \"resources/ch05-webpages/feed.json\"\n",
      "\n",
      "def extract_interactions(txt):\n",
      "    sentences = nltk.tokenize.sent_tokenize(txt)\n",
      "    tokens = [nltk.tokenize.word_tokenize(s) for s in sentences]\n",
      "    pos_tagged_tokens = [nltk.pos_tag(t) for t in tokens]\n",
      "\n",
      "    entity_interactions = []\n",
      "    for sentence in pos_tagged_tokens:\n",
      "\n",
      "        all_entity_chunks = []\n",
      "        previous_pos = None\n",
      "        current_entity_chunk = []\n",
      "\n",
      "        for (token, pos) in sentence:\n",
      "\n",
      "            if pos == previous_pos and pos.startswith('NN'):\n",
      "                current_entity_chunk.append(token)\n",
      "            elif pos.startswith('NN'):\n",
      "                if current_entity_chunk != []:\n",
      "                    all_entity_chunks.append((' '.join(current_entity_chunk),\n",
      "                            pos))\n",
      "                current_entity_chunk = [token]\n",
      "\n",
      "            previous_pos = pos\n",
      "\n",
      "        if len(all_entity_chunks) > 1:\n",
      "            entity_interactions.append(all_entity_chunks)\n",
      "        else:\n",
      "            entity_interactions.append([])\n",
      "\n",
      "    assert len(entity_interactions) == len(sentences)\n",
      "\n",
      "    return dict(entity_interactions=entity_interactions,\n",
      "                sentences=sentences)\n",
      "\n",
      "blog_data = json.loads(open(BLOG_DATA).read())\n",
      "\n",
      "# Display selected interactions on a per-sentence basis\n",
      "\n",
      "for post in blog_data:\n",
      "\n",
      "    post.update(extract_interactions(post['content']))\n",
      "\n",
      "    print post['title']\n",
      "    print '-' * len(post['title'])\n",
      "    for interactions in post['entity_interactions']:\n",
      "        print '; '.join([i[0] for i in interactions])\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LookupError",
       "evalue": "\n**********************************************************************\n  Resource u'taggers/averaged_perceptron_tagger/averaged_perceptro\n  n_tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Python27\\\\nltk_data'\n    - 'C:\\\\Python27\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-b78f1408657d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblog_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mpost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_interactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mpost\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-5-b78f1408657d>\u001b[0m in \u001b[0;36mextract_interactions\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpos_tagged_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mentity_interactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\tag\\__init__.pyc\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\tag\\perceptron.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\data.pyc\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource u'taggers/averaged_perceptron_tagger/averaged_perceptro\n  n_tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Python27\\\\nltk_data'\n    - 'C:\\\\Python27\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example 10. \u91c7\u7528HTML\u8f93\u51fa\u5bf9\u5b9e\u4f53\u95f4\u7684\u4ea4\u4e92\u53ef\u89c6\u5316"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import json\n",
      "import nltk\n",
      "from IPython.display import IFrame\n",
      "from IPython.core.display import display\n",
      "\n",
      "BLOG_DATA = \"resources/ch05-webpages/feed.json\"\n",
      "\n",
      "HTML_TEMPLATE = \"\"\"<html>\n",
      "    <head>\n",
      "        <title>%s</title>\n",
      "        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>\n",
      "    </head>\n",
      "    <body>%s</body>\n",
      "</html>\"\"\"\n",
      "\n",
      "blog_data = json.loads(open(BLOG_DATA).read())\n",
      "\n",
      "for post in blog_data:\n",
      "\n",
      "    post.update(extract_interactions(post['content']))\n",
      "\n",
      "    # Display output as markup with entities presented in bold text\n",
      "\n",
      "    post['markup'] = []\n",
      "\n",
      "    for sentence_idx in range(len(post['sentences'])):\n",
      "\n",
      "        s = post['sentences'][sentence_idx]\n",
      "        for (term, _) in post['entity_interactions'][sentence_idx]:\n",
      "            s = s.replace(term, '<strong>%s</strong>' % (term, ))\n",
      "\n",
      "        post['markup'] += [s] \n",
      "            \n",
      "    filename = post['title'].replace(\"?\", \"\") + '.entity_interactions.html'\n",
      "    f = open(os.path.join('resources', 'ch05-webpages', filename), 'w')\n",
      "    html = HTML_TEMPLATE % (post['title'] + ' Interactions', \n",
      "                            ' '.join(post['markup']),)\n",
      "    f.write(html.encode('utf-8'))\n",
      "    f.close()\n",
      "\n",
      "    print \"Data written to\", f.name\n",
      "    \n",
      "    # Display any of these files with an inline frame. This displays the\n",
      "    # last file processed by using the last value of f.name...\n",
      "    \n",
      "    print \"Displaying %s:\" % f.name\n",
      "    display(IFrame('files/%s' % f.name, '100%', '600px'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LookupError",
       "evalue": "\n**********************************************************************\n  Resource u'taggers/averaged_perceptron_tagger/averaged_perceptro\n  n_tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Python27\\\\nltk_data'\n    - 'C:\\\\Python27\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-6-c9d044d1d98b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblog_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mpost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_interactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Display output as markup with entities presented in bold text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-5-b78f1408657d>\u001b[0m in \u001b[0;36mextract_interactions\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpos_tagged_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mentity_interactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\tag\\__init__.pyc\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\tag\\perceptron.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\data.pyc\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource u'taggers/averaged_perceptron_tagger/averaged_perceptro\n  n_tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Python27\\\\nltk_data'\n    - 'C:\\\\Python27\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}